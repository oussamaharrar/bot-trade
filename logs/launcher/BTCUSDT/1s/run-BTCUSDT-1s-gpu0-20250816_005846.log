2025-08-16 00:58:51 | INFO | MainProcess | boot | ===== Logging started for BTCUSDT/1s =====
2025-08-16 00:58:51 | INFO | MainProcess | root | [PATHS] initialized for BTCUSDT | 1s
========== DEVICE REPORT ==========
torch.cuda.is_available(): True
CUDA device_count: 1
  [0] NVIDIA A100-SXM4-40GB
Selected device index: 0 -> NVIDIA A100-SXM4-40GB
torch.get_num_threads(): 6
===================================
2025-08-16 01:01:15 | INFO | MainProcess | root | [VECNORM] no previous running average found.
2025-08-16 01:01:15 | INFO | MainProcess | root | [ENV] action_space=Discrete(3) | is_discrete=True
C:\ProgramData\miniconda3\envs\bot-trade\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.
  warnings.warn(
2025-08-16 01:01:17 | INFO | MainProcess | root | [RESUME] Loaded model from agents\BTCUSDT\1s\deep_rl.zip
2025-08-16 01:01:17 | INFO | MainProcess | root | [\U0001f680] Training for total_steps=50000000 .
2025-08-16 01:09:35 | WARNING | MainProcess | root | [INTERRUPT] KeyboardInterrupt — saving.
2025-08-16 01:09:35 | INFO | MainProcess | root | [SAVE] model -> agents\BTCUSDT\1s\deep_rl.zip | vecnorm -> agents\BTCUSDT\1s\vecnorm.pkl
